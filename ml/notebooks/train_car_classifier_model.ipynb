{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg2m7OqBUNqt",
        "colab_type": "text"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LaySUqoRKcC",
        "colab_type": "text"
      },
      "source": [
        "#### Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS6BpLtZI8ib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52bd68ce-7c2c-469e-eba8-cbb8470dfcd2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeXpfBB7RVBb",
        "colab_type": "text"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlXkQ6qx_Xay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to import custom python files, append the path to sys here\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "from util import get_classes, process\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFB7kNs_MRLc",
        "colab_type": "text"
      },
      "source": [
        "#### Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74CbnuuJAx4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = '/content/drive/My Drive/Colab Notebooks/car_data/car_data'\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 196\n",
        "LEARNING_RATE = 0.1\n",
        "MOMENTUM = 0.9\n",
        "NUM_EPOCHS = 10\n",
        "VALIDATION_PERIOD = 20"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqxbm_QgRkmq",
        "colab_type": "text"
      },
      "source": [
        "# Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOqT-9GXA8F_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load datasets using ImageFolder structure\n",
        "train_data = torchvision.datasets.ImageFolder(f'{DATA_PATH}/train', transform=process.DATA_AUGMENT_TRANSFORM)\n",
        "test_data = torchvision.datasets.ImageFolder(f'{DATA_PATH}/test', transform=process.PREPROCESS_TRANSFORM)\n",
        "\n",
        "# create a validation set using 15% of the training data\n",
        "train_split = math.floor(0.85 * len(train_data))\n",
        "valid_split = math.ceil(0.15 * len(train_data))\n",
        "train_data, valid_data = torch.utils.data.random_split(train_data, [train_split, valid_split])\n",
        "\n",
        "# create data loaders using datasets, set shuffle to true so epochs are different\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M265WLOdJ3xV",
        "colab_type": "text"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1emIi-zkXNz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# also considering densenet121 and resnet34\n",
        "model = torchvision.models.resnet101(pretrained=True)\n",
        "num_input_filters = model.fc.in_features\n",
        "\n",
        "# define the fully-connected layer to be a linear transformation from num_input_filters to num_classes\n",
        "model.fc = torch.nn.Linear(num_input_filters, NUM_CLASSES)\n",
        "\n",
        "# use the gpu\n",
        "model.to('cuda')\n",
        "\n",
        "# define the criterion as the cross entropy loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# define the stochastic gradient descent with the learning rate and momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "\n",
        "# lower the learning rate when we stop improving as fast\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1j802WQKhRa",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3itog2-1hpy",
        "colab_type": "text"
      },
      "source": [
        "#### Validation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7OXITrCGu5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation function to calculate the loss\n",
        "def validation(model, valid_loader, criterion):\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "\n",
        "    # iterate over batches of validation data\n",
        "    for images, labels in valid_loader:\n",
        "        # move images and labels to gpu\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # forward the images through the model\n",
        "        output = model.forward(images)\n",
        "  \n",
        "        # sum the losses\n",
        "        loss += criterion(output, labels).item()\n",
        "  \n",
        "        # calculate a probability tensor by undoing log of loss function\n",
        "        probability = torch.exp(output)\n",
        "\n",
        "        # get the prediction\n",
        "        prediction = probability.max(dim=1)[1]\n",
        "\n",
        "        # sum average accuracy \n",
        "        accuracy += (labels.data == prediction).mean()\n",
        "    \n",
        "    loss = total_loss / len(valid_loader)\n",
        "    accuracy = total_accuracy / len(valid_loader)\n",
        "    \n",
        "    return loss, accuracy"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lziwB6x1ldj",
        "colab_type": "text"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBpYU-KpuyFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps = 0\n",
        "\n",
        "model.train()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0\n",
        "\n",
        "    # iterate over batches of training data\n",
        "    for images, labels in train_loader:\n",
        "        steps += 1\n",
        "\n",
        "        # move images and labels to gpu\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        \n",
        "        # zero out accumulated parameter gradients before doing back propagation \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward the images through the model\n",
        "        outputs = model.forward(images)\n",
        "\n",
        "        # back propagate the loss from the loss function to each parameter\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # validation step\n",
        "        if steps % VALIDATION_PERIOD == 0:\n",
        "            # set model to eval mode\n",
        "            model.eval()\n",
        "            \n",
        "            # turn gradients off during validation\n",
        "            with torch.no_grad():\n",
        "                validation_loss, accuracy = validation(model, valid_loader, criterion)\n",
        "            \n",
        "            # print each epoch\n",
        "            print(f'Epoch #: {epoch + 1}, \\\n",
        "            Running Loss: {running_loss / VALIDATION_PERIOD} \\\n",
        "            Validation Loss: {validation_loss} \\\n",
        "            Validation Accuracy: {accuracy}')\n",
        "            \n",
        "            # set model to train mode\n",
        "            model.train()\n",
        "\n",
        "            # slow learning rate according to validation loss\n",
        "            scheduler.step(validation_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVUhEZOal0OH",
        "colab_type": "text"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXyFWRKJIaqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c721d83-bc50-4a6d-bbc1-5cc8d5fc8c5d"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# test model using holdout test set with gradients off\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        # move images and labels to gpu\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # get model's probabilities of labels from images\n",
        "        outputs = model(images)\n",
        "\n",
        "        # get prediction\n",
        "        prediction = torch.max(outputs.data, dim=1)[1]\n",
        "\n",
        "        # sum number of correct predictions and total\n",
        "        total += labels.size(0)\n",
        "        correct += (prediction == labels).sum().item()\n",
        "\n",
        "print(f\"Test accuracy of model: {100 * correct / total}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy of model: 72.951%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dekV68M3Kufx",
        "colab_type": "text"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vcTL2RZBdDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the feature weights state, new fully connected layer, class-to-index map, optimiser state, and number of epochs\n",
        "checkpoint = {'state_dict': model.state_dict(),\n",
        "              'model': model.fc,\n",
        "              'class_to_idx': train_data.class_to_idx,\n",
        "              'opt_state': optimizer.state_dict,\n",
        "              'num_epochs': epochs\n",
        "              }\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "train_car_classifier_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9LaySUqoRKcC"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}