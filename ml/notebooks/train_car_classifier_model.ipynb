{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_car_classifier_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jvsMqs3BqZI",
        "colab_type": "text"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-DLRZcLBueU",
        "colab_type": "text"
      },
      "source": [
        "#### Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdAA4c_kBqMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "93ed918a-e739-4ceb-bf47-7c423332788b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbK4NTZPBxC7",
        "colab_type": "text"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzXEF2Y-BnGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to import custom python files, append the path to sys here\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "from util import get_classes, process\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yViVAO4KByZ8",
        "colab_type": "text"
      },
      "source": [
        "#### Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXvoIDJOCuKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = '/content/drive/My Drive/FindCar-shared/dataset'\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 196\n",
        "LEARNING_RATE = 0.1\n",
        "MOMENTUM = 0.9\n",
        "NUM_EPOCHS = 10\n",
        "VALIDATION_PERIOD = 20"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Ton48rCBjN",
        "colab_type": "text"
      },
      "source": [
        "# Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYMkzisKCDcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load datasets using ImageFolder structure\n",
        "dataset = torchvision.datasets.ImageFolder(DATA_PATH, transform=process.DATA_AUGMENT_TRANSFORM)\n",
        "test_data = torchvision.datasets.ImageFolder(DATA_PATH, transform=process.PREPROCESS_TRANSFORM)\n",
        "\n",
        "# create a validation set using 15% of the training data\n",
        "train_split = math.floor(0.85 * len(train_data))\n",
        "valid_split = math.ceil(0.15 * len(train_data))\n",
        "train_data, valid_data = torch.utils.data.random_split(dataset, [train_split, valid_split])\n",
        "\n",
        "# create data loaders using datasets, set shuffle to true so epochs are different\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03uSRuJGCFTU",
        "colab_type": "text"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62kc6Y1vCH3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# also considering densenet121 and resnet34\n",
        "model = torchvision.models.resnet101(pretrained=True)\n",
        "num_input_filters = model.fc.in_features\n",
        "\n",
        "# define the fully-connected layer to be a linear transformation from num_input_filters to num_classes\n",
        "model.fc = torch.nn.Linear(num_input_filters, NUM_CLASSES)\n",
        "\n",
        "# use the gpu\n",
        "model.to('cuda')\n",
        "\n",
        "# define the criterion as the cross entropy loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# define the stochastic gradient descent with the learning rate and momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "\n",
        "# lower the learning rate when we stop improving as fast\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PhzQpdgCJnz",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJGQc1WoCMZl",
        "colab_type": "text"
      },
      "source": [
        "#### Validation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iNTYXoJCPOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation function to calculate the loss\n",
        "def validation(model, valid_loader, criterion):\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "\n",
        "    # iterate over batches of validation data\n",
        "    for images, labels in valid_loader:\n",
        "        # move images and labels to gpu\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # forward the images through the model\n",
        "        output = model.forward(images)\n",
        "  \n",
        "        # sum the losses\n",
        "        loss += criterion(output, labels).item()\n",
        "  \n",
        "        # calculate a probability tensor by undoing log of loss function\n",
        "        probability = torch.exp(output)\n",
        "\n",
        "        # get the prediction\n",
        "        prediction = probability.max(dim=1)[1]\n",
        "\n",
        "        # sum average accuracy \n",
        "        accuracy += (labels.data == prediction).mean()\n",
        "    \n",
        "    loss = total_loss / len(valid_loader)\n",
        "    accuracy = total_accuracy / len(valid_loader)\n",
        "    \n",
        "    return loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekCL-1-8CROP",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3Xa2pLACS6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps = 0\n",
        "\n",
        "model.train()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    running_loss = 0\n",
        "\n",
        "    # iterate over batches of training data\n",
        "    for images, labels in train_loader:\n",
        "        steps += 1\n",
        "\n",
        "        # move images and labels to gpu\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        \n",
        "        # zero out accumulated parameter gradients before doing back propagation \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward the images through the model\n",
        "        outputs = model.forward(images)\n",
        "\n",
        "        # back propagate the loss from the loss function to each parameter\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # validation step\n",
        "        if steps % VALIDATION_PERIOD == 0:\n",
        "            # set model to eval mode\n",
        "            model.eval()\n",
        "            \n",
        "            # turn gradients off during validation\n",
        "            with torch.no_grad():\n",
        "                validation_loss, accuracy = validation(model, valid_loader, criterion)\n",
        "            \n",
        "            # print each epoch\n",
        "            print(f'Epoch #: {epoch + 1}, \\\n",
        "            Running Loss: {running_loss / VALIDATION_PERIOD} \\\n",
        "            Validation Loss: {validation_loss} \\\n",
        "            Validation Accuracy: {accuracy}')\n",
        "            \n",
        "            # set model to train mode\n",
        "            model.train()\n",
        "\n",
        "            # slow learning rate according to validation loss\n",
        "            scheduler.step(validation_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyNmg-UPCVCE",
        "colab_type": "text"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn9GRSDHCX3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# test model using holdout test set with gradients off\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        # move images and labels to gpu\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        # get model's probabilities of labels from images\n",
        "        outputs = model(images)\n",
        "\n",
        "        # get prediction\n",
        "        prediction = torch.max(outputs.data, dim=1)[1]\n",
        "\n",
        "        # sum number of correct predictions and total\n",
        "        total += labels.size(0)\n",
        "        correct += (prediction == labels).sum().item()\n",
        "\n",
        "print(f\"Test accuracy of model: {100 * correct / total}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEN_2G1vCaRs",
        "colab_type": "text"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBm0wnzTCcTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the feature weights state, new fully connected layer, class-to-index map, optimiser state, and number of epochs\n",
        "checkpoint = {'state_dict': model.state_dict(),\n",
        "              'model': model.fc,\n",
        "              'class_to_idx': train_data.class_to_idx,\n",
        "              'opt_state': optimizer.state_dict,\n",
        "              'num_epochs': epochs\n",
        "              }\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}